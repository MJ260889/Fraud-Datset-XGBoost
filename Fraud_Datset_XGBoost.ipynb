{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGlHVamsLgfZbZUljbG23F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MJ260889/Fraud-Datset-XGBoost/blob/main/Fraud_Datset_XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htb-qUlN_Lyt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('https://raw.githubusercontent.com/rashida048/Datasets/master/fraud_data.csv')"
      ],
      "metadata": {
        "id": "1igqSRfZ_RaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.dropna()"
      ],
      "metadata": {
        "id": "f3bN6w9uGYLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJm_RssuBiTR",
        "outputId": "7320f89b-506c-4513-b4e9-2dd439877830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21693 entries, 0 to 21692\n",
            "Data columns (total 30 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   V1      21693 non-null  float64\n",
            " 1   V2      21693 non-null  float64\n",
            " 2   V3      21693 non-null  float64\n",
            " 3   V4      21693 non-null  float64\n",
            " 4   V5      21693 non-null  float64\n",
            " 5   V6      21693 non-null  float64\n",
            " 6   V7      21693 non-null  float64\n",
            " 7   V8      21693 non-null  float64\n",
            " 8   V9      21693 non-null  float64\n",
            " 9   V10     21693 non-null  float64\n",
            " 10  V11     21693 non-null  float64\n",
            " 11  V12     21693 non-null  float64\n",
            " 12  V13     21693 non-null  float64\n",
            " 13  V14     21693 non-null  float64\n",
            " 14  V15     21693 non-null  float64\n",
            " 15  V16     21693 non-null  float64\n",
            " 16  V17     21693 non-null  float64\n",
            " 17  V18     21693 non-null  float64\n",
            " 18  V19     21693 non-null  float64\n",
            " 19  V20     21693 non-null  float64\n",
            " 20  V21     21693 non-null  float64\n",
            " 21  V22     21693 non-null  float64\n",
            " 22  V23     21693 non-null  float64\n",
            " 23  V24     21693 non-null  float64\n",
            " 24  V25     21693 non-null  float64\n",
            " 25  V26     21693 non-null  float64\n",
            " 26  V27     21693 non-null  float64\n",
            " 27  V28     21693 non-null  float64\n",
            " 28  Amount  21693 non-null  float64\n",
            " 29  Class   21693 non-null  int64  \n",
            "dtypes: float64(29), int64(1)\n",
            "memory usage: 5.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "di6QHkzfBkE-",
        "outputId": "3e5b0158-6770-4214-e74f-3351dcea0ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0  1.176563  0.323798  0.536927  1.047002 -0.368652 -0.728586  0.084678   \n",
              "1  0.681109 -3.934776 -3.801827 -1.147468 -0.735540 -0.501097  1.038865   \n",
              "2  1.140729  0.453484  0.247010  2.383132  0.343287  0.432804  0.093380   \n",
              "3 -1.107073 -3.298902 -0.184092 -1.795744  2.137564 -1.684992 -2.015606   \n",
              "4 -0.314818  0.866839 -0.124577 -0.627638  2.651762  3.428128  0.194637   \n",
              "\n",
              "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
              "0 -0.069246 -0.266389  0.155315  ... -0.109627 -0.341365  0.057845  0.499180   \n",
              "1 -0.626979 -2.274423  1.527782  ...  0.652202  0.272684 -0.982151  0.165900   \n",
              "2  0.173310 -0.808999  0.775436  ... -0.003802  0.058556 -0.121177 -0.304215   \n",
              "3 -0.007181 -0.165760  0.869659  ...  0.130648  0.329445  0.927656 -0.049560   \n",
              "4  0.670674 -0.442658  0.133499  ... -0.312774 -0.799494 -0.064488  0.953062   \n",
              "\n",
              "        V25       V26       V27       V28  Amount  Class  \n",
              "0  0.415211 -0.581949  0.015472  0.018065    4.67      0  \n",
              "1  0.360251  0.195321 -0.256273  0.056501  912.00      0  \n",
              "2  0.645893  0.122600 -0.012115 -0.005945    1.00      0  \n",
              "3 -1.892866 -0.575431  0.266573  0.414184   62.10      0  \n",
              "4 -0.429550  0.158225  0.076943 -0.015051    2.67      0  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e79e4bf-6539-40e5-87a3-b815e19cc253\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.176563</td>\n",
              "      <td>0.323798</td>\n",
              "      <td>0.536927</td>\n",
              "      <td>1.047002</td>\n",
              "      <td>-0.368652</td>\n",
              "      <td>-0.728586</td>\n",
              "      <td>0.084678</td>\n",
              "      <td>-0.069246</td>\n",
              "      <td>-0.266389</td>\n",
              "      <td>0.155315</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.109627</td>\n",
              "      <td>-0.341365</td>\n",
              "      <td>0.057845</td>\n",
              "      <td>0.499180</td>\n",
              "      <td>0.415211</td>\n",
              "      <td>-0.581949</td>\n",
              "      <td>0.015472</td>\n",
              "      <td>0.018065</td>\n",
              "      <td>4.67</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.681109</td>\n",
              "      <td>-3.934776</td>\n",
              "      <td>-3.801827</td>\n",
              "      <td>-1.147468</td>\n",
              "      <td>-0.735540</td>\n",
              "      <td>-0.501097</td>\n",
              "      <td>1.038865</td>\n",
              "      <td>-0.626979</td>\n",
              "      <td>-2.274423</td>\n",
              "      <td>1.527782</td>\n",
              "      <td>...</td>\n",
              "      <td>0.652202</td>\n",
              "      <td>0.272684</td>\n",
              "      <td>-0.982151</td>\n",
              "      <td>0.165900</td>\n",
              "      <td>0.360251</td>\n",
              "      <td>0.195321</td>\n",
              "      <td>-0.256273</td>\n",
              "      <td>0.056501</td>\n",
              "      <td>912.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.140729</td>\n",
              "      <td>0.453484</td>\n",
              "      <td>0.247010</td>\n",
              "      <td>2.383132</td>\n",
              "      <td>0.343287</td>\n",
              "      <td>0.432804</td>\n",
              "      <td>0.093380</td>\n",
              "      <td>0.173310</td>\n",
              "      <td>-0.808999</td>\n",
              "      <td>0.775436</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003802</td>\n",
              "      <td>0.058556</td>\n",
              "      <td>-0.121177</td>\n",
              "      <td>-0.304215</td>\n",
              "      <td>0.645893</td>\n",
              "      <td>0.122600</td>\n",
              "      <td>-0.012115</td>\n",
              "      <td>-0.005945</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.107073</td>\n",
              "      <td>-3.298902</td>\n",
              "      <td>-0.184092</td>\n",
              "      <td>-1.795744</td>\n",
              "      <td>2.137564</td>\n",
              "      <td>-1.684992</td>\n",
              "      <td>-2.015606</td>\n",
              "      <td>-0.007181</td>\n",
              "      <td>-0.165760</td>\n",
              "      <td>0.869659</td>\n",
              "      <td>...</td>\n",
              "      <td>0.130648</td>\n",
              "      <td>0.329445</td>\n",
              "      <td>0.927656</td>\n",
              "      <td>-0.049560</td>\n",
              "      <td>-1.892866</td>\n",
              "      <td>-0.575431</td>\n",
              "      <td>0.266573</td>\n",
              "      <td>0.414184</td>\n",
              "      <td>62.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.314818</td>\n",
              "      <td>0.866839</td>\n",
              "      <td>-0.124577</td>\n",
              "      <td>-0.627638</td>\n",
              "      <td>2.651762</td>\n",
              "      <td>3.428128</td>\n",
              "      <td>0.194637</td>\n",
              "      <td>0.670674</td>\n",
              "      <td>-0.442658</td>\n",
              "      <td>0.133499</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.312774</td>\n",
              "      <td>-0.799494</td>\n",
              "      <td>-0.064488</td>\n",
              "      <td>0.953062</td>\n",
              "      <td>-0.429550</td>\n",
              "      <td>0.158225</td>\n",
              "      <td>0.076943</td>\n",
              "      <td>-0.015051</td>\n",
              "      <td>2.67</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e79e4bf-6539-40e5-87a3-b815e19cc253')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e79e4bf-6539-40e5-87a3-b815e19cc253 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e79e4bf-6539-40e5-87a3-b815e19cc253');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ9V9mjWBm_7",
        "outputId": "75e132cb-a6ad-4a42-a930-f1424873a196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
              "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
              "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=df.iloc[:,:-1]\n",
        "x.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "JXixP_XEBqk0",
        "outputId": "5eb2ecd5-f4f9-4a21-a5c7-259966d5c5db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0  1.176563  0.323798  0.536927  1.047002 -0.368652 -0.728586  0.084678   \n",
              "1  0.681109 -3.934776 -3.801827 -1.147468 -0.735540 -0.501097  1.038865   \n",
              "2  1.140729  0.453484  0.247010  2.383132  0.343287  0.432804  0.093380   \n",
              "3 -1.107073 -3.298902 -0.184092 -1.795744  2.137564 -1.684992 -2.015606   \n",
              "4 -0.314818  0.866839 -0.124577 -0.627638  2.651762  3.428128  0.194637   \n",
              "\n",
              "         V8        V9       V10  ...       V20       V21       V22       V23  \\\n",
              "0 -0.069246 -0.266389  0.155315  ... -0.137258 -0.109627 -0.341365  0.057845   \n",
              "1 -0.626979 -2.274423  1.527782  ...  1.341809  0.652202  0.272684 -0.982151   \n",
              "2  0.173310 -0.808999  0.775436  ... -0.232185 -0.003802  0.058556 -0.121177   \n",
              "3 -0.007181 -0.165760  0.869659  ...  0.348269  0.130648  0.329445  0.927656   \n",
              "4  0.670674 -0.442658  0.133499  ...  0.402329 -0.312774 -0.799494 -0.064488   \n",
              "\n",
              "        V24       V25       V26       V27       V28  Amount  \n",
              "0  0.499180  0.415211 -0.581949  0.015472  0.018065    4.67  \n",
              "1  0.165900  0.360251  0.195321 -0.256273  0.056501  912.00  \n",
              "2 -0.304215  0.645893  0.122600 -0.012115 -0.005945    1.00  \n",
              "3 -0.049560 -1.892866 -0.575431  0.266573  0.414184   62.10  \n",
              "4  0.953062 -0.429550  0.158225  0.076943 -0.015051    2.67  \n",
              "\n",
              "[5 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d667be4-3ed4-42a1-b751-32f103f65f4f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.176563</td>\n",
              "      <td>0.323798</td>\n",
              "      <td>0.536927</td>\n",
              "      <td>1.047002</td>\n",
              "      <td>-0.368652</td>\n",
              "      <td>-0.728586</td>\n",
              "      <td>0.084678</td>\n",
              "      <td>-0.069246</td>\n",
              "      <td>-0.266389</td>\n",
              "      <td>0.155315</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.137258</td>\n",
              "      <td>-0.109627</td>\n",
              "      <td>-0.341365</td>\n",
              "      <td>0.057845</td>\n",
              "      <td>0.499180</td>\n",
              "      <td>0.415211</td>\n",
              "      <td>-0.581949</td>\n",
              "      <td>0.015472</td>\n",
              "      <td>0.018065</td>\n",
              "      <td>4.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.681109</td>\n",
              "      <td>-3.934776</td>\n",
              "      <td>-3.801827</td>\n",
              "      <td>-1.147468</td>\n",
              "      <td>-0.735540</td>\n",
              "      <td>-0.501097</td>\n",
              "      <td>1.038865</td>\n",
              "      <td>-0.626979</td>\n",
              "      <td>-2.274423</td>\n",
              "      <td>1.527782</td>\n",
              "      <td>...</td>\n",
              "      <td>1.341809</td>\n",
              "      <td>0.652202</td>\n",
              "      <td>0.272684</td>\n",
              "      <td>-0.982151</td>\n",
              "      <td>0.165900</td>\n",
              "      <td>0.360251</td>\n",
              "      <td>0.195321</td>\n",
              "      <td>-0.256273</td>\n",
              "      <td>0.056501</td>\n",
              "      <td>912.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.140729</td>\n",
              "      <td>0.453484</td>\n",
              "      <td>0.247010</td>\n",
              "      <td>2.383132</td>\n",
              "      <td>0.343287</td>\n",
              "      <td>0.432804</td>\n",
              "      <td>0.093380</td>\n",
              "      <td>0.173310</td>\n",
              "      <td>-0.808999</td>\n",
              "      <td>0.775436</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.232185</td>\n",
              "      <td>-0.003802</td>\n",
              "      <td>0.058556</td>\n",
              "      <td>-0.121177</td>\n",
              "      <td>-0.304215</td>\n",
              "      <td>0.645893</td>\n",
              "      <td>0.122600</td>\n",
              "      <td>-0.012115</td>\n",
              "      <td>-0.005945</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.107073</td>\n",
              "      <td>-3.298902</td>\n",
              "      <td>-0.184092</td>\n",
              "      <td>-1.795744</td>\n",
              "      <td>2.137564</td>\n",
              "      <td>-1.684992</td>\n",
              "      <td>-2.015606</td>\n",
              "      <td>-0.007181</td>\n",
              "      <td>-0.165760</td>\n",
              "      <td>0.869659</td>\n",
              "      <td>...</td>\n",
              "      <td>0.348269</td>\n",
              "      <td>0.130648</td>\n",
              "      <td>0.329445</td>\n",
              "      <td>0.927656</td>\n",
              "      <td>-0.049560</td>\n",
              "      <td>-1.892866</td>\n",
              "      <td>-0.575431</td>\n",
              "      <td>0.266573</td>\n",
              "      <td>0.414184</td>\n",
              "      <td>62.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.314818</td>\n",
              "      <td>0.866839</td>\n",
              "      <td>-0.124577</td>\n",
              "      <td>-0.627638</td>\n",
              "      <td>2.651762</td>\n",
              "      <td>3.428128</td>\n",
              "      <td>0.194637</td>\n",
              "      <td>0.670674</td>\n",
              "      <td>-0.442658</td>\n",
              "      <td>0.133499</td>\n",
              "      <td>...</td>\n",
              "      <td>0.402329</td>\n",
              "      <td>-0.312774</td>\n",
              "      <td>-0.799494</td>\n",
              "      <td>-0.064488</td>\n",
              "      <td>0.953062</td>\n",
              "      <td>-0.429550</td>\n",
              "      <td>0.158225</td>\n",
              "      <td>0.076943</td>\n",
              "      <td>-0.015051</td>\n",
              "      <td>2.67</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d667be4-3ed4-42a1-b751-32f103f65f4f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d667be4-3ed4-42a1-b751-32f103f65f4f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d667be4-3ed4-42a1-b751-32f103f65f4f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=df.iloc[:,-1]\n",
        "y.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW5hEW-AFNmh",
        "outputId": "d1193846-7c7a-4ba6-bfbe-920e83dff0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "lHjViqIAB2Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr,x_t,y_tr,y_t=train_test_split(x,y,test_size=.30)"
      ],
      "metadata": {
        "id": "iKNEga4CB4Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpLHh4KKGKO4",
        "outputId": "eceb02c4-1ee7-4a4a-ab7d-89507888a7ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15185, 29)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(XGBClassifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3DVHTLCB6JD",
        "outputId": "d785f938-801e-407b-9ab8-1546d9990f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class XGBClassifier in module xgboost.sklearn:\n",
            "\n",
            "class XGBClassifier(XGBModel, sklearn.base.ClassifierMixin)\n",
            " |  XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='binary:logistic', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, **kwargs)\n",
            " |  \n",
            " |  Implementation of the scikit-learn API for XGBoost classification.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  max_depth : int\n",
            " |      Maximum tree depth for base learners.\n",
            " |  learning_rate : float\n",
            " |      Boosting learning rate (xgb's \"eta\")\n",
            " |  n_estimators : int\n",
            " |      Number of trees to fit.\n",
            " |  verbosity : int\n",
            " |      The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
            " |  silent : boolean\n",
            " |      Whether to print messages while running boosting. Deprecated. Use verbosity instead.\n",
            " |  objective : string or callable\n",
            " |      Specify the learning task and the corresponding learning objective or\n",
            " |      a custom objective function to be used (see note below).\n",
            " |  booster: string\n",
            " |      Specify which booster to use: gbtree, gblinear or dart.\n",
            " |  nthread : int\n",
            " |      Number of parallel threads used to run xgboost.  (Deprecated, please use ``n_jobs``)\n",
            " |  n_jobs : int\n",
            " |      Number of parallel threads used to run xgboost.  (replaces ``nthread``)\n",
            " |  gamma : float\n",
            " |      Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
            " |  min_child_weight : int\n",
            " |      Minimum sum of instance weight(hessian) needed in a child.\n",
            " |  max_delta_step : int\n",
            " |      Maximum delta step we allow each tree's weight estimation to be.\n",
            " |  subsample : float\n",
            " |      Subsample ratio of the training instance.\n",
            " |  colsample_bytree : float\n",
            " |      Subsample ratio of columns when constructing each tree.\n",
            " |  colsample_bylevel : float\n",
            " |      Subsample ratio of columns for each level.\n",
            " |  colsample_bynode : float\n",
            " |      Subsample ratio of columns for each split.\n",
            " |  reg_alpha : float (xgb's alpha)\n",
            " |      L1 regularization term on weights\n",
            " |  reg_lambda : float (xgb's lambda)\n",
            " |      L2 regularization term on weights\n",
            " |  scale_pos_weight : float\n",
            " |      Balancing of positive and negative weights.\n",
            " |  base_score:\n",
            " |      The initial prediction score of all instances, global bias.\n",
            " |  seed : int\n",
            " |      Random number seed.  (Deprecated, please use random_state)\n",
            " |  random_state : int\n",
            " |      Random number seed.  (replaces seed)\n",
            " |  missing : float, optional\n",
            " |      Value in the data which needs to be present as a missing value. If\n",
            " |      None, defaults to np.nan.\n",
            " |  importance_type: string, default \"gain\"\n",
            " |      The feature importance type for the feature_importances_ property: either \"gain\",\n",
            " |      \"weight\", \"cover\", \"total_gain\" or \"total_cover\".\n",
            " |  \\*\\*kwargs : dict, optional\n",
            " |      Keyword arguments for XGBoost Booster object.  Full documentation of parameters can\n",
            " |      be found here: https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst.\n",
            " |      Attempting to set a parameter via the constructor args and \\*\\*kwargs dict simultaneously\n",
            " |      will result in a TypeError.\n",
            " |  \n",
            " |      .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
            " |  \n",
            " |          \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee that parameters\n",
            " |          passed via this argument will interact properly with scikit-learn.\n",
            " |  \n",
            " |  Note\n",
            " |  ----\n",
            " |  A custom objective function can be provided for the ``objective``\n",
            " |  parameter. In this case, it should have the signature\n",
            " |  ``objective(y_true, y_pred) -> grad, hess``:\n",
            " |  \n",
            " |  y_true: array_like of shape [n_samples]\n",
            " |      The target values\n",
            " |  y_pred: array_like of shape [n_samples]\n",
            " |      The predicted values\n",
            " |  \n",
            " |  grad: array_like of shape [n_samples]\n",
            " |      The value of the gradient for each sample point.\n",
            " |  hess: array_like of shape [n_samples]\n",
            " |      The value of the second derivative for each sample point\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      XGBClassifier\n",
            " |      XGBModel\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      sklearn.base.ClassifierMixin\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='binary:logistic', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, **kwargs)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  evals_result(self)\n",
            " |      Return the evaluation results.\n",
            " |      \n",
            " |      If **eval_set** is passed to the `fit` function, you can call\n",
            " |      ``evals_result()`` to get evaluation results for all passed **eval_sets**.\n",
            " |      When **eval_metric** is also passed to the `fit` function, the\n",
            " |      **evals_result** will contain the **eval_metrics** passed to the `fit` function.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      evals_result : dictionary\n",
            " |      \n",
            " |      Example\n",
            " |      -------\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          param_dist = {'objective':'binary:logistic', 'n_estimators':2}\n",
            " |      \n",
            " |          clf = xgb.XGBClassifier(**param_dist)\n",
            " |      \n",
            " |          clf.fit(X_train, y_train,\n",
            " |                  eval_set=[(X_train, y_train), (X_test, y_test)],\n",
            " |                  eval_metric='logloss',\n",
            " |                  verbose=True)\n",
            " |      \n",
            " |          evals_result = clf.evals_result()\n",
            " |      \n",
            " |      The variable **evals_result** will contain\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          {'validation_0': {'logloss': ['0.604835', '0.531479']},\n",
            " |          'validation_1': {'logloss': ['0.41965', '0.17686']}}\n",
            " |  \n",
            " |  fit(self, X, y, sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None, sample_weight_eval_set=None, callbacks=None)\n",
            " |      Fit gradient boosting classifier\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array_like\n",
            " |          Feature matrix\n",
            " |      y : array_like\n",
            " |          Labels\n",
            " |      sample_weight : array_like\n",
            " |          Weight for each instance\n",
            " |      eval_set : list, optional\n",
            " |          A list of (X, y) pairs to use as a validation set for\n",
            " |          early-stopping\n",
            " |      sample_weight_eval_set : list, optional\n",
            " |          A list of the form [L_1, L_2, ..., L_n], where each L_i is a list of\n",
            " |          instance weights on the i-th validation set.\n",
            " |      eval_metric : str, callable, optional\n",
            " |          If a str, should be a built-in evaluation metric to use. See\n",
            " |          doc/parameter.rst. If callable, a custom evaluation metric. The call\n",
            " |          signature is func(y_predicted, y_true) where y_true will be a\n",
            " |          DMatrix object such that you may need to call the get_label\n",
            " |          method. It must return a str, value pair where the str is a name\n",
            " |          for the evaluation and value is the value of the evaluation\n",
            " |          function. This objective is always minimized.\n",
            " |      early_stopping_rounds : int, optional\n",
            " |          Activates early stopping. Validation error needs to decrease at\n",
            " |          least every <early_stopping_rounds> round(s) to continue training.\n",
            " |          Requires at least one item in evals. If there's more than one,\n",
            " |          will use the last. If early stopping occurs, the model will have\n",
            " |          three additional fields: bst.best_score, bst.best_iteration and\n",
            " |          bst.best_ntree_limit (bst.best_ntree_limit is the ntree_limit parameter\n",
            " |          default value in predict method if not any other value is specified).\n",
            " |          (Use bst.best_ntree_limit to get the correct value if num_parallel_tree\n",
            " |          and/or num_class appears in the parameters)\n",
            " |      verbose : bool\n",
            " |          If `verbose` and an evaluation set is used, writes the evaluation\n",
            " |          metric measured on the validation set to stderr.\n",
            " |      xgb_model : str\n",
            " |          file name of stored xgb model or 'Booster' instance Xgb model to be\n",
            " |          loaded before training (allows training continuation).\n",
            " |      callbacks : list of callback functions\n",
            " |          List of callback functions that are applied at end of each iteration.\n",
            " |          It is possible to use predefined callbacks by using :ref:`callback_api`.\n",
            " |          Example:\n",
            " |      \n",
            " |          .. code-block:: python\n",
            " |      \n",
            " |              [xgb.callback.reset_learning_rate(custom_rates)]\n",
            " |  \n",
            " |  predict(self, data, output_margin=False, ntree_limit=None, validate_features=True)\n",
            " |      Predict with `data`.\n",
            " |      \n",
            " |      .. note:: This function is not thread safe.\n",
            " |      \n",
            " |        For each booster object, predict can only be called from one thread.\n",
            " |        If you want to run prediction using multiple thread, call ``xgb.copy()`` to make copies\n",
            " |        of model object and then call ``predict()``.\n",
            " |      \n",
            " |      .. note:: Using ``predict()`` with DART booster\n",
            " |      \n",
            " |        If the booster object is DART type, ``predict()`` will perform dropouts, i.e. only\n",
            " |        some of the trees will be evaluated. This will produce incorrect results if ``data`` is\n",
            " |        not the training data. To obtain correct results on test sets, set ``ntree_limit`` to\n",
            " |        a nonzero value, e.g.\n",
            " |      \n",
            " |        .. code-block:: python\n",
            " |      \n",
            " |          preds = bst.predict(dtest, ntree_limit=num_round)\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      data : DMatrix\n",
            " |          The dmatrix storing the input.\n",
            " |      output_margin : bool\n",
            " |          Whether to output the raw untransformed margin value.\n",
            " |      ntree_limit : int\n",
            " |          Limit number of trees in the prediction; defaults to best_ntree_limit if defined\n",
            " |          (i.e. it has been trained with early stopping), otherwise 0 (use all trees).\n",
            " |      validate_features : bool\n",
            " |          When this is True, validate that the Booster's and data's feature_names are identical.\n",
            " |          Otherwise, it is assumed that the feature_names are the same.\n",
            " |      Returns\n",
            " |      -------\n",
            " |      prediction : numpy array\n",
            " |  \n",
            " |  predict_proba(self, data, ntree_limit=None, validate_features=True)\n",
            " |      Predict the probability of each `data` example being of a given class.\n",
            " |      \n",
            " |      .. note:: This function is not thread safe\n",
            " |      \n",
            " |          For each booster object, predict can only be called from one thread.\n",
            " |          If you want to run prediction using multiple thread, call ``xgb.copy()`` to make copies\n",
            " |          of model object and then call predict\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      data : DMatrix\n",
            " |          The dmatrix storing the input.\n",
            " |      ntree_limit : int\n",
            " |          Limit number of trees in the prediction; defaults to best_ntree_limit if defined\n",
            " |          (i.e. it has been trained with early stopping), otherwise 0 (use all trees).\n",
            " |      validate_features : bool\n",
            " |          When this is True, validate that the Booster's and data's feature_names are identical.\n",
            " |          Otherwise, it is assumed that the feature_names are the same.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      prediction : numpy array\n",
            " |          a numpy array with the probability of each data example being of a given class.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from XGBModel:\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  apply(self, X, ntree_limit=0)\n",
            " |      Return the predicted leaf every tree for each sample.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array_like, shape=[n_samples, n_features]\n",
            " |          Input features matrix.\n",
            " |      \n",
            " |      ntree_limit : int\n",
            " |          Limit number of trees in the prediction; defaults to 0 (use all trees).\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_leaves : array_like, shape=[n_samples, n_trees]\n",
            " |          For each datapoint x in X and for each tree, return the index of the\n",
            " |          leaf x ends up in. Leaves are numbered within\n",
            " |          ``[0; 2**(self.max_depth+1))``, possibly with gaps in the numbering.\n",
            " |  \n",
            " |  get_booster(self)\n",
            " |      Get the underlying xgboost Booster of this model.\n",
            " |      \n",
            " |      This will raise an exception when fit was not called\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      booster : a xgboost booster of underlying model\n",
            " |  \n",
            " |  get_num_boosting_rounds(self)\n",
            " |      Gets the number of xgboost boosting rounds.\n",
            " |  \n",
            " |  get_params(self, deep=False)\n",
            " |      Get parameters.\n",
            " |  \n",
            " |  get_xgb_params(self)\n",
            " |      Get xgboost type parameters.\n",
            " |  \n",
            " |  load_model(self, fname)\n",
            " |      Load the model from a file.\n",
            " |      \n",
            " |      The model is loaded from an XGBoost internal binary format which is\n",
            " |      universal among the various XGBoost interfaces. Auxiliary attributes of\n",
            " |      the Python Booster object (such as feature names) will not be loaded.\n",
            " |      Label encodings (text labels to numeric labels) will be also lost.\n",
            " |      **If you are using only the Python interface, we recommend pickling the\n",
            " |      model object for best results.**\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      fname : string or a memory buffer\n",
            " |          Input file name or memory buffer(see also save_raw)\n",
            " |  \n",
            " |  save_model(self, fname)\n",
            " |      Save the model to a file.\n",
            " |      \n",
            " |      The model is saved in an XGBoost internal binary format which is\n",
            " |      universal among the various XGBoost interfaces. Auxiliary attributes of\n",
            " |      the Python Booster object (such as feature names) will not be loaded.\n",
            " |      Label encodings (text labels to numeric labels) will be also lost.\n",
            " |      **If you are using only the Python interface, we recommend pickling the\n",
            " |      model object for best results.**\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      fname : string\n",
            " |          Output file name\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      Modification of the sklearn method to allow unknown kwargs. This allows using\n",
            " |      the full range of xgboost parameters that are not defined as member variables\n",
            " |      in sklearn grid search.\n",
            " |      Returns\n",
            " |      -------\n",
            " |      self\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from XGBModel:\n",
            " |  \n",
            " |  coef_\n",
            " |      Coefficients property\n",
            " |      \n",
            " |      .. note:: Coefficients are defined only for linear learners\n",
            " |      \n",
            " |          Coefficients are only defined when the linear model is chosen as base\n",
            " |          learner (`booster=gblinear`). It is not defined for other base learner types, such\n",
            " |          as tree learners (`booster=gbtree`).\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      coef_ : array of shape ``[n_features]`` or ``[n_classes, n_features]``\n",
            " |  \n",
            " |  feature_importances_\n",
            " |      Feature importances property\n",
            " |      \n",
            " |      .. note:: Feature importance is defined only for tree boosters\n",
            " |      \n",
            " |          Feature importance is only defined when the decision tree model is chosen as base\n",
            " |          learner (`booster=gbtree`). It is not defined for other base learner types, such\n",
            " |          as linear learners (`booster=gblinear`).\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      feature_importances_ : array of shape ``[n_features]``\n",
            " |  \n",
            " |  intercept_\n",
            " |      Intercept (bias) property\n",
            " |      \n",
            " |      .. note:: Intercept is defined only for linear learners\n",
            " |      \n",
            " |          Intercept (bias) is only defined when the linear model is chosen as base\n",
            " |          learner (`booster=gblinear`). It is not defined for other base learner types, such\n",
            " |          as tree learners (`booster=gbtree`).\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      intercept_ : array of shape ``(1,)`` or ``[n_classes]``\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  score(self, X, y, sample_weight=None)\n",
            " |      Return the mean accuracy on the given test data and labels.\n",
            " |      \n",
            " |      In multi-label classification, this is the subset accuracy\n",
            " |      which is a harsh metric since you require for each sample that\n",
            " |      each label set be correctly predicted.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Test samples.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          True labels for `X`.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=XGBClassifier(n_estimator=90,max_depth=3)"
      ],
      "metadata": {
        "id": "JybkfQJvCXTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_tr,y_tr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9R8bvAMCcs8",
        "outputId": "c9513c27-4dec-4667-cef7-56036b0d1ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(n_estimator=90)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,classification_report"
      ],
      "metadata": {
        "id": "yaJ63jDKCgLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict=model.predict(x_t)\n",
        "y_predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntEkdebJCiTX",
        "outputId": "873fb5dd-c3a8-4c88-ed3f-d95aaaf5689f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_t,y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P7914BaCkhY",
        "outputId": "4991f58c-928c-4992-caeb-1e06522ed055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9960049170251998"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_t,y_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMLS4y7TCnOe",
        "outputId": "a0bed187-1114-4b70-a931-089f6cd5b13a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      6386\n",
            "           1       0.98      0.80      0.88       122\n",
            "\n",
            "    accuracy                           1.00      6508\n",
            "   macro avg       0.99      0.90      0.94      6508\n",
            "weighted avg       1.00      1.00      1.00      6508\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sklearn.metrics.ConfusionMatrixDisplay.from_predictions(y_t,y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "8I5CzxrgCpfr",
        "outputId": "affa0ae3-d794-4a2b-8dd9-c33181b1832c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f46bca58150>"
            ]
          },
          "metadata": {},
          "execution_count": 142
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "dir(sklearn.metrics.ConfusionMatrixDisplay.from_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71iedZDJCt_f",
        "outputId": "2f39d7f0-e115-4499-a620-9802680b006e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__call__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__func__',\n",
              " '__ge__',\n",
              " '__get__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__self__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__']"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fR9mK8ZbC6Do"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}